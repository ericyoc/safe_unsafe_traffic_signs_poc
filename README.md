This project provides a comprehensive framework for generating and analyzing synthetic traffic sign images, specifically focusing on **Yield signs, Stop signs, and Upward Arrow signs**. It adheres to MUTCD (Manual on Uniform Traffic Control Devices) safety standards, leveraging **Google Colab** for execution and requiring **Google Drive** to be mounted for efficient file management and persistent storage.

### Overview

  * The core of this project involves generating a diverse **dataset** of these three traffic sign types with controlled safety parameters.
  * This is achieved using a **Conditional Generative Adversarial Network (GAN)**, which is fundamentally built upon **Convolutional Neural Networks (CNNs)**.
  * The GAN allows for the creation of both MUTCD-compliant (safe) and non-compliant (unsafe) signs by manipulating key visual properties like reflectivity and contrast according to predefined rules.
  * The project also incorporates robust **directory services** to manage the generated image files and other project assets within the Colab environment.

**Importance for Safety:**

  * This project is crucial for road safety as it addresses the challenge of acquiring diverse and representative datasets for training robust computer vision models.
  * By synthesizing signs under various conditions (e.g., different lighting, degradation levels, and material properties that affect reflectivity and contrast), we can train AI systems to accurately detect and classify traffic signs even when they are partially obscured, faded, or otherwise compromised.
  * This directly contributes to safer autonomous driving systems and improved traffic infrastructure monitoring.

### Installation

To set up the environment in Google Colab, execute the following command to install the necessary Python packages:

```bash
pip install torch torchvision opencv-python wget matplotlib pillow
```

You will also need to mount your Google Drive at the beginning of your Colab session to ensure the project can access and save files for persistent storage.

### Dataset Generation

The synthetic dataset for **Yield, Stop, and Upward Arrow signs** is generated by controlling three key parameters for each replica. These parameters serve as the explicit "rules" or conditions for the GAN to follow during image synthesis:

  * **Legend Reflectivity (Legend\_Ra)**: The light reflected from the text or symbol on the sign.
  * **Background Reflectivity (Background\_Ra)**: The light reflected from the sign's background.
  * **Contrast (Contrast\_val)**: The ratio of reflectivity between the legend and the background.

The `generate_balanced_parameters` function ensures a balanced distribution of "SAFE" and "UNSAFE" signs for each type. The classification of a sign as "SAFE" or "UNSAFE" is strictly determined by comparing these generated reflectivity and contrast parameters against predefined **MUTCD minimum thresholds**. For example, a "Yield" sign is classified as "UNSAFE" if its legend reflectivity, background reflectivity, or contrast falls below the specified MUTCD minimums. This rule-based labeling of "SAFE" vs. "UNSAFE" for each generated image forms the ground truth for training downstream **CNN classifiers**.

The generated images and their associated metadata (including safety status, reflectivity, and contrast values) are then saved, forming a labeled dataset suitable for training.

### Conditional GAN (CNN)

A **3-Condition Conditional GAN** is employed to synthesize the traffic sign images. The Generator and Discriminator networks within this GAN are both deep **Convolutional Neural Networks (CNNs)**:

  * **Generator Network**: This CNN-based architecture (`Generator` class) takes two inputs: an initial segmented sign image and a condition vector (comprising the Legend\_Ra, Background\_Ra, and Contrast\_val). Its role is to learn how to transform the input image to match the visual characteristics dictated by the condition vector. Essentially, the Generator's CNN learns the complex "rules" of how changes in reflectivity and contrast *visually manifest* on a traffic sign.
  * **Discriminator Network**: This CNN-based architecture (`Discriminator` class) acts as a critic. It also takes both an image and the corresponding condition vector as input. Its task is to distinguish whether the input image is a "real" (target) image or a "fake" (generated by the Generator) image, conditioned on the given parameters. The Discriminator's CNN learns features that differentiate realistic sign appearances from unrealistic ones under various conditions.

The GAN is trained using a combination of adversarial loss (`BCELoss`) and pixel-wise similarity loss (`L1Loss`). This training process enables the CNN-based Generator to produce realistic variations of traffic signs with precise control over their visual properties, essential for simulating diverse real-world conditions that a real-world CNN classifier would encounter.

### Directory Services

The project includes utility functions for managing directories within the Google Colab environment and mounted Google Drive:

  * `list_directory_contents(directory_path)`: Lists all files and subdirectories within a specified path.
  * `remove_specific_directories(base_directory="/content")`: Recursively deletes predefined output directories (e.g., `arrow_replicas_balanced`, `yield_replicas_balanced`, `stop_replicas_balanced`) to ensure clean runs and manage storage. This is particularly important when working with large generated datasets in Google Colab's ephemeral file system, allowing for easy cleanup and organization of potentially thousands of generated images.

### Model Evaluation Summary

The provided evaluation metrics are for a **downstream CNN classifier** trained on the generated dataset. These metrics demonstrate the effectiveness of using the synthetically generated data to train a CNN for classifying traffic signs as safe or unsafe based on the MUTCD rules embedded in the dataset generation:

| Dataset    | Accuracy | Loss  | True Positives (SAFE) | True Negatives (UNSAFE) | False Positives (UNSAFE as SAFE) | False Negatives (SAFE as UNSAFE) | Precision (SAFE) | Recall (SAFE) |
|------------|----------|-------|-----------------------|-------------------------|----------------------------------|----------------------------------|------------------|---------------|
| Training   | 0.9395   | 0.158 | 3138                  | 2766                    | 384                              | 12                               | 0.8910           | 0.9962        |
| Test       | 0.9304   | -     | 675                   | 581                     | 94                               | 0                                | 0.8778           | 1.0000        |
| Validation | 0.9467   | -     | 675                   | 603                     | 72                               | 0                                | 0.9036           | 1.0000        |

These metrics indicate that the CNN classifier performs well in distinguishing between safe and unsafe traffic signs based on the parameters it was trained on, showing high accuracy and recall for safe signs, validating the utility of the synthetic dataset.
